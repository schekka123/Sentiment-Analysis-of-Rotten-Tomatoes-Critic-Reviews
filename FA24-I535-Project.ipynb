{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad196064-3394-44b5-aec4-86e027cb11c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1130017 entries, 0 to 1130016\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count    Dtype \n",
      "---  ------                --------------    ----- \n",
      " 0   rotten_tomatoes_link  1130017 non-null  object\n",
      " 1   critic_name           1111488 non-null  object\n",
      " 2   top_critic            1130017 non-null  bool  \n",
      " 3   publisher_name        1130017 non-null  object\n",
      " 4   review_type           1130017 non-null  object\n",
      " 5   review_score          824081 non-null   object\n",
      " 6   review_date           1130017 non-null  object\n",
      " 7   review_content        1064211 non-null  object\n",
      "dtypes: bool(1), object(7)\n",
      "memory usage: 61.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  rotten_tomatoes_link      critic_name  top_critic           publisher_name  \\\n",
       " 0            m/0814255  Andrew L. Urban       False           Urban Cinefile   \n",
       " 1            m/0814255    Louise Keller       False           Urban Cinefile   \n",
       " 2            m/0814255              NaN       False      FILMINK (Australia)   \n",
       " 3            m/0814255     Ben McEachen       False  Sunday Mail (Australia)   \n",
       " 4            m/0814255      Ethan Alter        True       Hollywood Reporter   \n",
       " \n",
       "   review_type review_score review_date  \\\n",
       " 0       Fresh          NaN  2010-02-06   \n",
       " 1       Fresh          NaN  2010-02-06   \n",
       " 2       Fresh          NaN  2010-02-09   \n",
       " 3       Fresh        3.5/5  2010-02-09   \n",
       " 4      Rotten          NaN  2010-02-10   \n",
       " \n",
       "                                       review_content  \n",
       " 0  A fantasy adventure that fuses Greek mythology...  \n",
       " 1  Uma Thurman as Medusa, the gorgon with a coiff...  \n",
       " 2  With a top-notch cast and dazzling special eff...  \n",
       " 3  Whether audiences will get behind The Lightnin...  \n",
       " 4  What's really lacking in The Lightning Thief i...  ,\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded dataset to inspect the columns and data types\n",
    "file_path = \"C:/Users/saidh/Downloads/rotten_tomatoes_critic_reviews/rotten_tomatoes_critic_reviews.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows and summary information\n",
    "data.head(), data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf01fceb-765b-4613-bd25-d351d07b2323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values per Column:\n",
      " rotten_tomatoes_link         0\n",
      "critic_name              18529\n",
      "top_critic                   0\n",
      "publisher_name               0\n",
      "review_type                  0\n",
      "review_score            305936\n",
      "review_date                  0\n",
      "review_content           65806\n",
      "dtype: int64\n",
      "\n",
      "Unique Values per Column:\n",
      "Column 'rotten_tomatoes_link': ['m/0814255' 'm/0878835' 'm/10' 'm/1000013-12_angry_men'\n",
      " 'm/1000079-20000_leagues_under_the_sea' 'm/10000_bc' 'm/1000121-39_steps'\n",
      " 'm/1000123-310_to_yuma' 'm/10002008-charly' 'm/1000204-abraham_lincoln']...\n",
      "Column 'critic_name': ['Andrew L. Urban' 'Louise Keller' nan 'Ben McEachen' 'Ethan Alter'\n",
      " 'David Germain' 'Nick Schager' 'Bill Goodykoontz' 'Jordan Hoffman'\n",
      " 'Jim Schembri']...\n",
      "Column 'top_critic': [False  True]...\n",
      "Column 'publisher_name': ['Urban Cinefile' 'FILMINK (Australia)' 'Sunday Mail (Australia)'\n",
      " 'Hollywood Reporter' 'Associated Press' 'Slant Magazine'\n",
      " 'Arizona Republic' 'UGO' 'The Age (Australia)' 'Daily Mirror (UK)']...\n",
      "Column 'review_type': ['Fresh' 'Rotten']...\n",
      "Column 'review_score': [nan '3.5/5' '1/4' 'B' '3/5' '4/5' '2/4' '2/5' 'C' '2.5/4']...\n",
      "Column 'review_date': ['2010-02-06' '2010-02-09' '2010-02-10' '2010-02-11' '2010-02-12'\n",
      " '2010-02-13' '2010-02-14' '2010-02-16' '2010-02-17' '2010-02-18']...\n",
      "Column 'review_content': ['A fantasy adventure that fuses Greek mythology to contemporary American places and values. Anyone around 15 (give or take a couple of years) will thrill to the visual spectacle'\n",
      " 'Uma Thurman as Medusa, the gorgon with a coiffure of writhing snakes and stone-inducing hypnotic gaze is one of the highlights of this bewitching fantasy'\n",
      " 'With a top-notch cast and dazzling special effects, this will tide the teens over until the next Harry Potter instalment.'\n",
      " \"Whether audiences will get behind The Lightning Thief is hard to predict. Overall, it's an entertaining introduction to a promising new world -- but will the consuming shadow of Potter be too big to break free of?\"\n",
      " \"What's really lacking in The Lightning Thief is a genuine sense of wonder, the same thing that brings viewers back to Hogwarts over and over again.\"\n",
      " \"It's more a list of ingredients than a movie-magic potion to enjoy from start to finish.\"\n",
      " \"Harry Potter knockoffs don't come more transparent and slapdash than this wannabe-franchise jumpstarter directed by Chris Columbus.\"\n",
      " \"Percy Jackson isn't a great movie, but it's a good one, trotting out kernels of Greek mythology like so many Disney Channel references.\"\n",
      " 'Fun, brisk and imaginative'\n",
      " 'Crammed with dragons, set-destroying fights and things exploding, [Columbus] squeezes in a few well-meaning pause breaks about friendship and absent fathers before swiftly moving on to the next pyrotechnics display.']...\n",
      "\n",
      "Data Types of Columns:\n",
      " rotten_tomatoes_link    object\n",
      "critic_name             object\n",
      "top_critic                bool\n",
      "publisher_name          object\n",
      "review_type             object\n",
      "review_score            object\n",
      "review_date             object\n",
      "review_content          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1. Count of missing values in each column\n",
    "na_counts = data.isna().sum()\n",
    "\n",
    "# 2. Unique values for each column\n",
    "unique_values = {col: data[col].unique() for col in data.columns}\n",
    "\n",
    "# 3. Data type summary\n",
    "data_info = data.dtypes\n",
    "\n",
    "# Display results\n",
    "print(\"Missing Values per Column:\\n\", na_counts)\n",
    "print(\"\\nUnique Values per Column:\")\n",
    "for col, values in unique_values.items():\n",
    "    print(f\"Column '{col}': {values[:10]}...\")  # Display only the first 10 unique values for brevity\n",
    "\n",
    "print(\"\\nData Types of Columns:\\n\", data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0debcbea-200a-4ba3-a8ed-ae1ba530de37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saidh\\AppData\\Local\\Temp\\ipykernel_3928\\2785744938.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['review_score'] = data_cleaned['review_score'].apply(extract_score)\n",
      "C:\\Users\\saidh\\AppData\\Local\\Temp\\ipykernel_3928\\2785744938.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['review_date'] = pd.to_datetime(data_cleaned['review_date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Step 1: Drop rows with missing `review_content` (essential for sentiment analysis)\n",
    "data_cleaned = data.dropna(subset=['review_content'])\n",
    "\n",
    "# Step 2: Handle missing values in `review_score`\n",
    "# Attempt to standardize `review_score` to numeric values where possible\n",
    "def extract_score(score):\n",
    "    if pd.isna(score):\n",
    "        return None\n",
    "    # Extract numeric part, e.g., \"3.5/5\" -> 3.5, \"70%\" -> 70, or return None for non-standard formats\n",
    "    match = re.match(r'(\\d+(\\.\\d+)?)', str(score))\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "data_cleaned['review_score'] = data_cleaned['review_score'].apply(extract_score)\n",
    "\n",
    "# Step 3: Convert `review_date` to datetime format\n",
    "data_cleaned['review_date'] = pd.to_datetime(data_cleaned['review_date'], errors='coerce')\n",
    "\n",
    "# Step 4: Drop rows with missing values in columns still necessary for analysis\n",
    "data_cleaned = data_cleaned.dropna(subset=['critic_name', 'review_type', 'review_date'])\n",
    "\n",
    "# Step 5: Select relevant columns for analysis\n",
    "columns_to_keep = [\n",
    "    'rotten_tomatoes_link', 'critic_name', 'top_critic', 'publisher_name', \n",
    "    'review_type', 'review_score', 'review_date', 'review_content'\n",
    "]\n",
    "data_final = data_cleaned[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d7c94d-1164-49cd-bcd2-162f51394a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types of Columns in data_final:\n",
      " rotten_tomatoes_link            object\n",
      "critic_name                     object\n",
      "top_critic                        bool\n",
      "publisher_name                  object\n",
      "review_type                     object\n",
      "review_score                   float64\n",
      "review_date             datetime64[ns]\n",
      "review_content                  object\n",
      "dtype: object\n",
      "Column 'rotten_tomatoes_link' has consistent data type.\n",
      "Column 'critic_name' has consistent data type.\n",
      "Column 'top_critic' has consistent data type.\n",
      "Column 'publisher_name' has consistent data type.\n",
      "Column 'review_type' has consistent data type.\n",
      "Column 'review_score' has consistent data type.\n",
      "Column 'review_date' has consistent data type.\n",
      "Column 'review_content' has consistent data type.\n",
      "\n",
      "Sample Data:\n",
      "   rotten_tomatoes_link      critic_name  top_critic           publisher_name  \\\n",
      "0            m/0814255  Andrew L. Urban       False           Urban Cinefile   \n",
      "1            m/0814255    Louise Keller       False           Urban Cinefile   \n",
      "3            m/0814255     Ben McEachen       False  Sunday Mail (Australia)   \n",
      "4            m/0814255      Ethan Alter        True       Hollywood Reporter   \n",
      "5            m/0814255    David Germain        True         Associated Press   \n",
      "\n",
      "  review_type  review_score review_date  \\\n",
      "0       Fresh           NaN  2010-02-06   \n",
      "1       Fresh           NaN  2010-02-06   \n",
      "3       Fresh           3.5  2010-02-09   \n",
      "4      Rotten           NaN  2010-02-10   \n",
      "5      Rotten           NaN  2010-02-10   \n",
      "\n",
      "                                      review_content  \n",
      "0  A fantasy adventure that fuses Greek mythology...  \n",
      "1  Uma Thurman as Medusa, the gorgon with a coiff...  \n",
      "3  Whether audiences will get behind The Lightnin...  \n",
      "4  What's really lacking in The Lightning Thief i...  \n",
      "5  It's more a list of ingredients than a movie-m...  \n"
     ]
    }
   ],
   "source": [
    "# Display the data types of each column\n",
    "print(\"Data Types of Columns in data_final:\\n\", data_final.dtypes)\n",
    "\n",
    "# Check for any rows with mixed types in each column by verifying consistent data types\n",
    "# Summarize data type checks\n",
    "for column in data_final.columns:\n",
    "    unique_types = data_final[column].apply(type).nunique()\n",
    "    if unique_types > 1:\n",
    "        print(f\"Column '{column}' contains mixed data types.\")\n",
    "    else:\n",
    "        print(f\"Column '{column}' has consistent data type.\")\n",
    "\n",
    "# Display the first few rows of the dataframe for a quick inspection\n",
    "print(\"\\nSample Data:\\n\", data_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8869e13f-3742-4fdf-97e0-fc0173be9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data\n",
    "output_path = 'C:/Users/saidh/Downloads/rotten_tomatoes_critic_reviews/rotten_tomatoes_critic_reviews_cleaned.csv'\n",
    "data_final.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df940f03-8456-41ad-a992-70ef0da348d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1054198 entries, 0 to 1130016\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count    Dtype         \n",
      "---  ------                --------------    -----         \n",
      " 0   rotten_tomatoes_link  1054198 non-null  object        \n",
      " 1   critic_name           1054198 non-null  object        \n",
      " 2   top_critic            1054198 non-null  bool          \n",
      " 3   publisher_name        1054198 non-null  object        \n",
      " 4   review_type           1054198 non-null  object        \n",
      " 5   review_score          630853 non-null   float64       \n",
      " 6   review_date           1054198 non-null  datetime64[ns]\n",
      " 7   review_content        1054198 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), object(5)\n",
      "memory usage: 65.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9270ee62-a2b1-4e7f-a5f6-d66196c6d6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-language\n",
      "  Downloading google_cloud_language-2.15.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (2.1.3)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language)\n",
      "  Downloading google_api_core-2.22.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 (from google-cloud-language)\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-language)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-language)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from pandas) (2023.3)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (1.59.3)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language)\n",
      "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-language) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-language) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-language) (4.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language)\n",
      "  Downloading grpcio-1.67.1-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-language) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saidh\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (2023.11.17)\n",
      "Downloading google_cloud_language-2.15.0-py2.py3-none-any.whl (153 kB)\n",
      "   ---------------------------------------- 0.0/153.8 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 61.4/153.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 153.8/153.8 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.22.0-py3-none-any.whl (156 kB)\n",
      "   ---------------------------------------- 0.0/156.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 156.5/156.5 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 209.5/209.5 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.5 kB ? eta -:--:--\n",
      "   ---------------------------------------  430.1/431.5 kB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 431.5/431.5 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/220.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 220.9/220.9 kB 14.0 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.67.1-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio-1.67.1-cp310-cp310-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.6/4.4 MB 19.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.7/4.4 MB 17.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.4/4.4 MB 17.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.6/4.4 MB 20.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.4/4.4 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 18.5 MB/s eta 0:00:00\n",
      "Installing collected packages: protobuf, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-api-core, google-cloud-language\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.59.3\n",
      "    Uninstalling grpcio-1.59.3:\n",
      "      Successfully uninstalled grpcio-1.59.3\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.24.0\n",
      "    Uninstalling google-auth-2.24.0:\n",
      "      Successfully uninstalled google-auth-2.24.0\n",
      "Successfully installed google-api-core-2.22.0 google-auth-2.36.0 google-cloud-language-2.15.0 googleapis-common-protos-1.65.0 grpcio-1.67.1 grpcio-status-1.67.1 proto-plus-1.25.0 protobuf-5.28.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "onnx 1.12.0 requires protobuf<=3.20.1,>=3.12.2, but you have protobuf 5.28.3 which is incompatible.\n",
      "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 5.28.3 which is incompatible.\n",
      "tensorflow 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 5.28.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-language pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db3d009-99f2-47a0-b52b-e2f31858dd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58044fac-d057-4a8c-b760-8f85200c69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable for authentication\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/saidh/Downloads/fa24-i535-ksdhanus-moviereview-6f36c0289e17.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fdf5c67-2fdc-4d25-870b-ada48f023159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sentiment analysis on review content...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                             | 9/2109 [08:39<33:40:59, 57.74s/it]\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Quota exceeded for quota metric 'Requests' and limit 'Requests per minute' of service 'language.googleapis.com' for consumer 'project_number:612483773688'. [reason: \"RATE_LIMIT_EXCEEDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"language.googleapis.com\"\n}\nmetadata {\n  key: \"quota_metric\"\n  value: \"language.googleapis.com/default_requests\"\n}\nmetadata {\n  key: \"quota_location\"\n  value: \"global\"\n}\nmetadata {\n  key: \"quota_limit\"\n  value: \"DefaultRequestsPerMinutePerProject\"\n}\nmetadata {\n  key: \"quota_limit_value\"\n  value: \"600\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/612483773688\"\n}\n, links {\n  description: \"Request a higher quota limit.\"\n  url: \"https://cloud.google.com/docs/quotas/help/request_increase\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data), batch_size)):\n\u001b[0;32m     25\u001b[0m     batch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[start:start\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m---> 26\u001b[0m     batch_results \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43manalyze_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotnull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(batch_results)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Split results into two columns and assign to DataFrame\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[13], line 26\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data), batch_size)):\n\u001b[0;32m     25\u001b[0m     batch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[start:start\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m---> 26\u001b[0m     batch_results \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43manalyze_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotnull(x) \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m     27\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(batch_results)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Split results into two columns and assign to DataFrame\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 15\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_sentiment\u001b[39m(text):\n\u001b[0;32m     14\u001b[0m     document \u001b[38;5;241m=\u001b[39m language_v1\u001b[38;5;241m.\u001b[39mDocument(content\u001b[38;5;241m=\u001b[39mtext, type_\u001b[38;5;241m=\u001b[39mlanguage_v1\u001b[38;5;241m.\u001b[39mDocument\u001b[38;5;241m.\u001b[39mType\u001b[38;5;241m.\u001b[39mPLAIN_TEXT, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m     sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocument\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdocument_sentiment\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiment\u001b[38;5;241m.\u001b[39mscore, sentiment\u001b[38;5;241m.\u001b[39mmagnitude\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\google\\cloud\\language_v1\\services\\language_service\\client.py:759\u001b[0m, in \u001b[0;36mLanguageServiceClient.analyze_sentiment\u001b[1;34m(self, request, document, encoding_type, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    758\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 759\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 Quota exceeded for quota metric 'Requests' and limit 'Requests per minute' of service 'language.googleapis.com' for consumer 'project_number:612483773688'. [reason: \"RATE_LIMIT_EXCEEDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"language.googleapis.com\"\n}\nmetadata {\n  key: \"quota_metric\"\n  value: \"language.googleapis.com/default_requests\"\n}\nmetadata {\n  key: \"quota_location\"\n  value: \"global\"\n}\nmetadata {\n  key: \"quota_limit\"\n  value: \"DefaultRequestsPerMinutePerProject\"\n}\nmetadata {\n  key: \"quota_limit_value\"\n  value: \"600\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/612483773688\"\n}\n, links {\n  description: \"Request a higher quota limit.\"\n  url: \"https://cloud.google.com/docs/quotas/help/request_increase\"\n}\n]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import language_v1\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Set up the Google Language API client\n",
    "client = language_v1.LanguageServiceClient()\n",
    "\n",
    "# Load the reviews dataset\n",
    "data = pd.read_csv('C:/Users/saidh/Downloads/rotten_tomatoes_critic_reviews/rotten_tomatoes_critic_reviews_cleaned.csv')\n",
    "\n",
    "# Function to analyze sentiment of text\n",
    "def analyze_sentiment(text):\n",
    "    document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT, language=\"en\")\n",
    "    sentiment = client.analyze_sentiment(request={\"document\": document}).document_sentiment\n",
    "    return sentiment.score, sentiment.magnitude\n",
    "\n",
    "# Process data in batches and add a progress bar\n",
    "batch_size = 500  # Set batch size, e.g., 500 reviews per batch\n",
    "results = []\n",
    "\n",
    "print(\"Starting sentiment analysis on review content...\")\n",
    "\n",
    "for start in tqdm(range(0, len(data), batch_size)):\n",
    "    batch = data.iloc[start:start+batch_size]\n",
    "    batch_results = batch['review_content'].apply(lambda x: analyze_sentiment(str(x)) if pd.notnull(x) else (None, None))\n",
    "    results.extend(batch_results)\n",
    "\n",
    "# Split results into two columns and assign to DataFrame\n",
    "sentiment_scores, sentiment_magnitudes = zip(*results)\n",
    "data['sentiment_score'] = sentiment_scores\n",
    "data['sentiment_magnitude'] = sentiment_magnitudes\n",
    "\n",
    "# Display a sample of the DataFrame to verify results\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4df643-8a69-45c9-8f0d-809daa3aa13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
